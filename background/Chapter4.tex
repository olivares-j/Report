%!TEX root = ../thesis.tex
\chapter{Results}
\label{chap:Results}
In this Chapter I characterise the methodology detailed in Chapter  \ref{chap:BHM} and then I applied it to the Pleiades DANCe DR2 data set (Sect. \ref{sect:DR2}). To characterise the methodology as a classifier, I measure its precision and accuracy when applied on synthetic data where the true members of the cluster are known. With this characterisation, I am able to obtain an optimal probability threshold, but only for classification purposes. Afterwards, I apply the methodology to the Pleiades DANCe RDR2 and I find the candidate members of the cluster using the optimal probability threshold. Then, I compare these candidate members with those found by previous studies.

Later, I analyse the main results of this work, those that fulfil the objective: the statistical distributions that characterise of the cluster population. Then, l give the details of the spatial, velocity, luminosity and mass distributions. Finally, I end this Chapter describing the physical scenario of the evolution of the mass distribution of the Pleiades by comparing it with other mass distribution of younger and older clusters.

\section{Performance of the classifier}
\label{sect:classifier}
As mentioned earlier, the main objective of the methodology of the BHM is the statistical characterisation of the NYOC populations. However, as a by product, it also obtains the individual membership probability distributions of the objects comprising the data set. These membership probability distributions, together with a probability threshold, allow a direct classification of the objects into cluster and field members.  The classification resulting from this procedure, as any other measured property, has an uncertainty. By evaluating this uncertainty under the results of synthetic data (in which the true members are known) we are able to measure the accuracy and precision of the classification process as a function of the probability threshold used. This section explains how an objective probability threshold can be found by maximising the accuracy of the classifier. 

To measure the accuracy of our classifier, I test it over synthetic data sets that resemble the real RDR2 (Section \ref{sect:RDR2}). An ideal test to our classifier will be to apply it over well known dataset in which tags of cluster and field members were already present. However, if we may have access to these tags, a classifier may not be needed. The Pleiades cluster being one of the most studied cluster in history, it is the NYOC with most of these tags (see Section \ref{sect:memberscomparison}). This is one the reasons for which we decided to benchmark our methodology on it. In spite of the large number of candidate members for the Pleiades clusters, the synthetic data and its true tags are still needed. The reasons are the following. First, the list of candidate members provided by the literature is not infallible. We can never be sure that this list is complete and unpolluted. Here it is important to note that the astrophysical domain of the phenomenon marks a very important distinction with common supervised classification methods. A perfect and real training set is not available. It must be created from simulations. Second, even if the most probable candidate members from the literature were used as a training set \cite[as done for example by][]{Sarro2014} the very faint end of the magnitude distribution (represented by brown-dwarfs) is still a \emph{terra ignota} where candidate members are scarce or not even exist. 

Thus, to overcome the problem of the true tags, we decided to create synthetic data sets. These synthetic true tags, and therefore, the results obtained from them relay under the assumption that our cluster and field models resemble the real data. I am aware that these models are far from perfect, but so far this assumption provides the best option. Although this assumption enable us to quantify the internal consistence (precision and accuracy) of our classifier, it does not give any indication about possible biases in the model. To explore this possibility, in the next Section, I compare our real data classification results with those of the literature.

The random nature of the synthetic data sets demands the repetition of the data sets and results. This repetitions avoid any bias caused by excursions of the random number generator (bad luck), and more importantly, they allow us to compute the uncertainty in the accuracy and precision of the classifier. As explained before, the methodology presented in this work is computing demanding. Thus, to be able to repeat at least five times the results of the synthetic data sets, we further reduce the data set size. The inference process in a data set of $10^4$ objects demands almost week of computing time. Thus, we decided that such data set provided a good compromise between computing time and number of objects. Furthermore, to provide a better estimate of the contamination rate on the results over the real RDR2 data set (the one with the $10^5$ objects) we chose to work with the $10^4$ objects with high membership probability according to \citet{Bouy2015}. Since this sample is relatively more entangled with the cluster than that of the RDR2, we assume that the contamination rate we measure on this sample will be comparable or even higher than that hypothetically obtained over the $10^5$ RDR2. 

Briefly, to create the synthetic data set, the procedure is the following. First, using the methodology of the previous Chapter, I obtain a sample of the posterior distribution of the parameters in the model given the $10^4$ real data set. Then, I chose the particle with highest posterior probability as the MAP estimate of the posterior distribution. Using this particle positions in the parametric space, I generate five synthetic data sets of $10^4$ objects each. Then, I tag these objects according to their parent population: cluster or field. Afterwards, using the vector of synthetic values of each object, I assign their uncertainties and missing value entries (more details  below).

Finally, I run the methodology over the five synthetic data sets, and obtain a sample of the individual membership probability distributions of each synthetic object. Then, I compare the true tags with the measured ones as function of the probability threshold. 

To further test the performance of the classifier, I apply it on a synthetic data set in two different cases. In the first case the data set is one of the five synthetic ones. Thus it contains objects with missing value entries in their vector of observables.  In the second case the data set is the same as in the previous case, but this time all the objects have fully observed vectors (i.e. do not have missing value entries). The comparison of the results rendered by these two cases allows us to quantify the impact of missing values. 

Objects in the Pleiades DANCe DR2  have full observed proper motions vectors. Since missing values appear only in the photometric vectors, in synthetic data sets I only include missing values in the photometry. Only $\sim1\%$ of the objects in the RDR2 have full observed vectors (i.e. no missing value entries). Furthermore, the distribution of missing entries is not random and depends on the magnitudes of the objects (see Fig. \ref{fig:NAsKs}). Therefore, to better reproduce this distribution in the synthetic data sets, for each synthetic datum, I use the mask of missing entries of one of its closer neighbours in the real data set. Here, distance is measured in the euclidean sense. If I were to use the missing value mask of the nearest neighbour in the real data set, then I will obtain a biased sample in which objects with full observed vectors (with no missing entries) will be underestimated. This is the inevitable consequence of the fact that euclidean distances measured in subspaces, which result from removing the dimensions of the missing entries, are small, or at most equal, than those measured in the complete space. 

To reproduce the mask of missing entries, I chose from among those masks of the closer neighbours in the available CMDs: $\{K_s,J-K_s\},\{J,J-H\},\{K_s,H-K_s\},\{J,Y-J\},\{K_s,i-K_s\}$. These CMD are formed with the bands and colours of the magnitudes with fewer missing values, in decreasing order (see Table \ref{tab:DR2properties}).  The missing entries mask to reproduce in the synthetic objects is chosen as follows. First, for each CMD subspace I find the set of objects, from the real data set, with fully observed entries, I call it $C_{or,i}$ and its fraction from the total, $f_r$. Then, I take a random sample from the synthetic data whose fraction, $f_s$ equals $f_r$. For objects in this sample I assign the missing value pattern of the nearest neighbour in $C_{or,i}$. I repeat this procedure for the rest of the CMDs. In this way, the synthetic data sets have fractions of objects with and without missing entries, similar to those of the objects in the real data set.

To assign uncertainties I proceed as follows. For uncertainties in the proper motions I use those of the nearest neighbour from the real data set. If I were to use the nearest neighbour scheme for uncertainties in the photometry, then I will obtain biased results. These uncertainties will be biased towards those of the less precise measurements. Again, this is a consequence of the missing entries in the observable vectors. The euclidean metric results in the preferential choosing of objects with missing values. These missing values occur mostly at the faint end, where uncertainties are larger. Therefore, these uncertainties will be biased towards these larger values. To avoid this issue, I fit 8th degree Chebyshev polynomials to the uncertainties as a function of the magnitudes. Then, I use these polynomials to establish the photometric uncertainties of the synthetic data sets.

Once the synthetic data sets were created I run the methodology on each of them and recover the membership probability distribution of each object. Then, I classify each object as cluster or field member. To classify an object as a cluster member, the mode of its cluster membership probability distribution must be higher than the probability threshold. Otherwise it is classified as a field object. 

The classifier performance was measured by counting the true positives (TP, cluster members correctly classified), true negatives (TN, field members correctly classified), false positives (FP, field members classified as cluster members) and false negatives (FN, cluster members classified as field members) recoveries as a function of the probability threshold. With them I calculate the following quantities: the true positive rate (TPR), which is the ratio of true positives over the sum of true positives plus false negatives, the contamination rate (CR), which is the ratio of false positives over the sum of false positives plus true positives, the precision or positive predictive value (PPV), which is the ratio of true positives over the sum of true positives plus false positives, and, the accuracy (ACC), which is the ratio of the sum of true positives plus true negative over the sum of true and false positives and negatives. 

These are,
\begin{align}
TPR &= \frac{TP}{TP+FN} \nonumber \\
CR   &= \frac{FP}{FP+TP} \nonumber \\
PPV &= \frac{TP}{TP+FP} \nonumber \\
ACC &= \frac{TP+TN}{TN+FN+TP+FP},\nonumber
\end{align}
which are defined at each probability threshold. I use the results of the five synthetic data sets to quantify the uncertainties of the previous quantities. 

In Fig. \ref{fig:TPR-CR}, I show the mean and uncertainty of the TPR and CR measured on the five synthetic data sets. The uncertainty is represented by the maximum deviation from the mean. Also, this Figure shows the TPR and CR measured on a synthetic data set with fully observed objects (i.e. objects with non missing entries). As this Figure shows, the missing values have a negative impact in our classification. They diminish the TPR  and increase the CR. This negative impact is expected since the observables we are using are highly discriminant in the classification process (see Section \ref{sect:RF-2}). Since cluster and field are highly entangled in the $10^4$ objects synthetic samples, when one of these observables is missing the classification is more uncertain or it could even be biased. Interestingly, the CR above probability threshold 0.8 is independent of the missing values and remains low ($\lesssim 5\%$). In spite of the negative impact of missing values, the methodology delivers low contamination rates ($\lesssim 5-10\%$) and high recovery rates ($\lesssim 90-96\%$) for probability thresholds in the $0.5-0.9$ range. 

In Figure \ref{fig:TPR-CR}, I also show the CR and TPR of \citet{Sarro2014} (reported in their Table 4). Previous to discuss the differences between both works I inform the reader about the unfairness of this comparison. First, in the works of \citet{Sarro2014} and \citet{Bouy2015}, the generative models are constructed using only fully observed objects (i.e. without missing entries), these objects represent only  $\sim 1\%$ of our RDR2. Afterwards, they apply those models to all the objects in the DANCe DR2 data set (i.e. objects with and without missing entries). Thus, their results are more similar to those I find on the synthetic data set with only fully observed objects (blue lines in Fig. \ref{fig:TPR-CR}). Second, the synthetic data sets in which both works measure the TPR and CR are different. They are constructed with different generative models, different number of objects, and different missing value distributions.

From the comparison between \citet{Sarro2014} TPR and CR, with the ones I find on the synthetic data set comprising only fully observed objects, we see the following. The TPR of both works agree within the uncertainties. The CR of both works agree, within the reported uncertainties, for probability thresholds below 0.8. At higher probability thresholds, our methodology delivers lower CR. Even in the case of the unfair comparison between the TPR and CR of \citet{Sarro2014} with those I measure on the synthetic data sets including objects with missing entries, our CR outperforms that reported by \citet{Sarro2014} at the small price of a lower ($\approx 4\%$) TPR.

Now, I describe the procedure to set an optimal probability threshold. This probability threshold, although not needed to obtain the posterior distribution of the parameters modelling the cluster population, is needed, however, to objectively classify an object as a cluster member. I establish this threshold using only the synthetic data sets containing objects with missing entries in their vector of measurements.  The approach I use to set this probability threshold is that of the maximum accuracy (ACC) for the classification. 

Figure \ref{fig:ACC} shows the ACC and the PPV of the classifier when when it is applied on synthetic data sets containing objects with missing value entries. The lines and the grey regions depict, respectively, the mean and the maximum deviations of the results of the five synthetic data sets. The maximum deviation is used as a proxy for the uncertainty. The highest mean accuracy, ACC=$96.5\pm0.1$\%, happens at probability threshold $p_t = 0.84$. Thus, I chose it as the optimal classification threshold. At this value, the CR is $4.3\pm0.2$\%, the TPR is $90.0\pm0.05$\%, and the PPV is $95.6\pm0.2$\%. 

\begin{figure}[ht!]
\begin{center}
\resizebox{0.8\textwidth}{!}{\includegraphics{background/Figures/FTPRvsSarro.pdf}}
\caption{The mean TPR (solid line) and CR (dashed line) resulting from five synthetic data sets including objects with missing entries (red lines). Also the TPR and CR resulting from a synthetic data set comprising only objects with fully observed vectors (blue lines). The shaded regions (grey) show the uncertainties computed from the five synthetic data sets. The black dots show the TPR and CR reported by \citet{Sarro2014} for their model. See text for warnings on this comparison. Reproduced from Figure 3 of \citet{Olivares2017},\textit{\usebibentry{Olivares2017}{title}}, \usebibentry{Olivares2017}{journal}, \usebibentry{Olivares2017}{volume}.}
\label{fig:TPR-CR}
\end{center}
\end{figure}

\begin{figure}[ht!]
\begin{center}
\resizebox{0.8\textwidth}{!}{\includegraphics{background/Figures/PrecisionAccuracy.pdf}}
\caption{Mean accuracy (ACC, solid line) and precision (PPV, dashed line) of the classifier as a function of probability threshold. The shaded regions shows the uncertainties computed from the five synthetic data sets. The higher accuracy is obtained at $p_t=0.84$ (red dot). Reproduced from Figure 3 of \citet{Olivares2017},\textit{\usebibentry{Olivares2017}{title}}, \usebibentry{Olivares2017}{journal}, \usebibentry{Olivares2017}{volume}.}
\label{fig:ACC}
\end{center}
\end{figure}

We investigate further on the impact that objects with missing value entries in their observations vectors have on our methodology. Particularly, in the following I analyse possible biases introduced by these objects. To do this, I compare the membership probabilities, summarised by the mode, recovered after inferring the model on two synthetic data sets of. These two data sets are identical except that in one of them some entries in the vector of observables where masked as missing (using the procedure previously described).

In Fig. \ref{figure:IncVsCom}, I compare the mode of the membership probabilities. The horizontal axis shows the membership probabilities of the data set with fully observed objects (I call this case the complete one). The vertical axis shows the membership probabilities of the same objects but in which some entries were masked as missing (I call this case the Incomplete one). As can be seen in this Fig., the missing values impact our results by spreading the membership probabilities. Ideally, we would like to recover membership probabilities following the line of slope one. This is the case of some fully observed objects (red squares) in the data set containing objects with missing entries. The most striking deviations come from those objects with the $CI$ masked as missing (enclosed in black). The BHM methodology uses the \emph{true} $CI$ to prescribe the \emph{true} photometry. Also, it uses the observed $CI$ to constrain the marginalisation integral of the \emph{true} $CI$. Thus, as expected, a missing $CI$ produces a spread in the membership probability. 

The objects with a missing $CI$ show two different behaviours. In one case, there are objects with membership probabilities from the fully observed data set (horizontal axis) that have an overestimated membership probability in the missing entries data set (vertical axis). In the other case, there are objects that have underestimated probabilities in the missing entries data set. These objects correspond to those seen in the combed area below the line of unit slope. 

Objects in the first case increase the CR, and their effect can be seen by the difference between red and blue dashed lines in Fig. \ref{fig:TPR-CR}. On the other hand, the objects in the second case diminish the TPR, their effect can also be seen by the difference between red and blue solid lines in Fig. \ref{fig:TPR-CR}. The increase in CR reaches its maximum near probability zero in the horizontal axis (Complete case) and goes to zero at probability thresholds of $\approx 0.9$. Therefore, the impact this increased CR has in our results is marginal. For example, at the optimal probability threshold $p_t=0.84$, the increase of CR due to objects with missing entries represent only 1.8\%. This correspond to the objects in box region of Fig. \ref{figure:IncVsCom} (upper left corner). However, the objects in the second case, those that diminish the TPR, represent the typical unavoidable loss of members due to their missing entries. These amount to a 4\% loss in the TPR, at the optimal probability threshold, $p_t=0.84$.


The bias introduced in the recovered membership probabilities due to objects with missing value entries, can be quantified using the root-mean-square (rms) of the difference between the means of the two recovered membership probabilities (Complete and Incomplete cases). The total rms is 0.12. On the one hand, fully observed objects in both data sets (Complete and Incomplete cases) have a rms of only 0.02. On the other hand, objects with missing entries, excluding those with missing $CI$, have a rms of 0.08. The rms of objects lacking the $CI$ is 0.14. The previous effects show an overall agreement between results on data sets with and without objects with missing entries. Nonetheless, care must be taken when dealing with individual membership probabilities. An object with a missing value in the $Y,J,H$ and $K_s$ may have a diminished membership probability (with a rms of 0.08), while an object with a missing $CI$ may show an increased membership probability (with a rms of 0.14).  


However, as have been mentioned before, the methodology described in this work aims at the statistical distributions of the cluster population. The individual membership probabilities are just a useful by product. The methodology develop here, though, works by ensuring that each object contributes to the posterior distribution of the parameters modelling the cluster population, proportionally to its cluster membership probability. In this sense our results are free of any possible bias introduced by cuts in the membership probability. Nevertheless, there is still contamination, particularly from objects with missing entries, as seen before. This contamination in the statistical distributions that we aim to obtain must be quantified. To do this, I compute the expected value of the CR found in this section. It is $\langle CR \rangle=5.8\pm 0.2$\%. In this expected value, each CR contributes proportionally to the probability threshold at which it is measured. Since the vast contribution to this CR coms from probability thresholds below 0.2 (see Fig. \ref{fig:TPR-CR}), the expected value of the CR remains low. 

\begin{figure}[!htp]
\begin{center}
\resizebox{0.8\textwidth}{!}{\includegraphics[page=1]{background/Figures/Probabilities.pdf}}
\caption{Comparison between the cluster membership probabilities recovered from the synthetic data set with objects having missing value entries (vertical axis, labeled Incomplete), and, the synthetic data set with fully observed objects (horizontal axis, labeled Complete). The colour and shape indicate the amount of missing entries. The symbols enclosed in black indicate a missing $CI$. The top left box contains objects considered as contaminants due to missing values at the probability threshold $p_t=0.84$. Reproduced from Figure 4 of \citet{Olivares2017},\textit{\usebibentry{Olivares2017}{title}}, \usebibentry{Olivares2017}{journal}, \usebibentry{Olivares2017}{volume}.}
\label{figure:IncVsCom}
\end{center}
\end{figure}

In statistical science, particularly in machine learining, is sometimes useful to analyse the performance of a binary classifier by the receiver operating characteristic curve, the ROC curve. It plots a visual diagnostic of the ability of a classifier to perform its job. The ROC curve plots the TPR as a function of the FPR for all possible values of the probability threshold. A perfect classifier would be that in which the TPR=1 and the FPR=0 for some probability threshold. On the other hand, a random classifier would be that with TPR=FPR at all probability thresholds. Such classifier has a line of slope one in its ROC curve. Furthermore, the quantitative diagnostic for a binary classifier is the area under the ROC curve (AUC). As its name indicate, the AUC is the integral of the ROC curve. Thus a random classifier has a AUC of one half, while a perfect classifier has a AUC=1. In Fig. \ref{fig:ROC}, I show the ROC curve for our classifier when applied over synthetic data containing objects with missing entries. It is the ROC of one of the five synthetic realisations described throughout this section. As can bee seen from this Figure our classifier does an excellent job, with an AUC=0.992.

\begin{figure}[!htp]
\begin{center}
\resizebox{0.8\textwidth}{!}{\includegraphics{background/Figures/ROC.pdf}}
\caption{ROC curve of the BHM by-product classifier when applied on the synthetic data set containing objects with missing entries. As can be seen, the AUC=0.992 diagnose it as an excellent classifier.}
\label{fig:ROC}
\end{center}
\end{figure}

 
\section{Comparison with the literature}
\label{sect:memberscomparison}
In Chapter \ref{chap:pleiades}, I mentioned that the most important works on the Pleiades members are those of \citet{Stauffer2007,Lodieu2012,Sarro2014,Bouy2015}. In this section I will compare the list of candidate I members found with the most recent study of the Pleiades members, that of \citet{Bouy2015}. Later, for the sake of completeness, I will compare my list of candidate members with the compilation made by \citet{Stauffer2007}.  

IS ALL THIS SECTIONING REQUIRED.

REJECTED CANDIDATES? OF WHOM? BY WHOM? AVOID CONFUSSION.

\subsection{Candidate members from \citet{Stauffer2007}}

REFER AS LIST I AND LIST II AVOID CONFUSION.

\citet{Stauffer2007} published two list of candidate members. The first one contains 1417 objects compiled from the literature (their Table 2). These objects were classified as candidate members by several authors along modern astronomy. As \citet{Stauffer2007} mention, this list is inhomogeneous, incomplete and certainly includes non members. Their second list contains 55 candidate members  (their Table 5) found using infrared photometry, and proper motions.

Cross matching these two lists with the candidate members of\citet{Bouy2015}, shows that only 1288 of the 1417 objects on \citet{Stauffer2007} Table 2 were classified by \citet{Bouy2015} as candidate members. From these, 1132 objects come from the DANce survey and the rest from Tycho+DANCe, see Appendix B of \citet{Bouy2015}. Also, only 34 of the 55 new candidate members of  \citet{Stauffer2007} were classified by \citet{Bouy2015} as candidate members. In Figures \ref{fig:Stauffer1} - \ref{fig:Stauffer2} I show the candidate members of \citet{Stauffer2007}, and \citet{Bouy2015}. As mentioned by \citet{Stauffer2007}, many of the candidate members in their Table 2 are most probably non members. These objects lay far from the locus of the rest of the candidates. Similarly, the majority of the rejected candidates of \citet{Stauffer2007}, 15 of those in their Table 5, lay far from the cluster proper motion and photometric loci.

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{./background/Figures/Stauffer2Bouy_PM.pdf}
\includegraphics[width=\textwidth]{./background/Figures/Stauffer2Bouy_CMD.pdf}
\caption{Comparison between proper motions (top) and $K$ vs $i-K$ CMD of the candidate members compiled by \citet{Stauffer2007} (red) and those of \citet{Bouy2015}(blue), the common candidates are shown within green squares. }
\label{fig:Stauffer1}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{./background/Figures/Stauffer5Bouy_PM.pdf}
\includegraphics[width=\textwidth]{./background/Figures/Stauffer5Bouy_CMD.pdf}
\caption{Comparison between proper motions (top) and $K$ vs $i-K$ CMD of the new candidate members of \citet{Stauffer2007} (red) and those of \citet{Bouy2015}(blue), the common candidates are shown within green squares. }
\label{fig:Stauffer2}
\end{center}
\end{figure}
 
Concerning our list of candidate members, after cross matching the lists, we recover 1139 of the candidate members from Table 2 of  \citet{Stauffer2007}. Seven more than \citet{Bouy2015}. Also, we recover the same 34 candidates that \citet{Bouy2015} recovered from the new candidates of \citet{Stauffer2007} (from their Table5). 

I have already mentioned that the Table 2 of \citet{Stauffer2007} is an exhaustive compilation of Pleiades members. This list contains objects that authors from the literature classified as Pleiades members even when the membership probability was as low as 0.1 \citep{Stauffer2007}. Therefore, I will not analyse in detail the $\sim 300$ rejected objects. It suffices to mention that we recover an slightly larger (seven) number of candidates than \citet{Bouy2015}.

On the other hand, the list of new candidate members of \citet{Stauffer2007} deserves further attention and a more detailed comparison.
From the 21 rejected objects, 14 of them lay below the cluster photometric sequence and  far from the proper motion locus. The remaining seven have membership probabilities near our probability threshold. XXXXX CHECK THIS XXXX 
\subsection{Candidate members from \citet{Bouy2015}}
\label{sect:comparisonBouy}
The methodology of this work, although essentially different from that of \citet{Bouy2015}, the fact that both share the data set and use the same observables, allows a direct comparison between them. When using their objective probability thresholds, as shown by Fig. \ref{figure:HM-SBB}, both methodologies agree on the outstanding $99.6$\% of the classified objects. Concerning the candidate members, they also agree on $\approx 90\%$ of them. Nevertheless, the discrepancies are worthy of discussion.

The rejected candidates of \citet{Bouy2015} (lower right box of Fig. \ref{figure:HM-SBB}) amount to 12\% of their total number of candidate members. This value is 4.7\% higher than the contamination rate reported by \citet{Sarro2014}: $7.3\pm1.4$\%. I will not reject a priori these objects as candidate members because, as mentioned in Sect. \ref{sect:classifier}, our methodology recovers 4\% less members when compared to that of \citet{Sarro2014}(see Fig. \ref{fig:tfpr}). The majority, $85\%$, of these objects have missing values, which indicates that these objects require future follow up. Even the 37 completely observed and rejected candidates can not be discarded as true members due to the fact that our methodology losses 6\% of the true cluster members (see Fig. \ref{fig:tfpr}).  

CHANGE THIS PARAGRAPH. THE SAMPLES ARE NOT THE SAME THUS 10\% IS MEANINGLESS.On the other hand, our new candidates (upper left box of Fig. \ref{figure:HM-SBB} ) amount to 10\% of \citet{Bouy2015} candidates. This figure is higher than the $4.3\pm0.2$\% CR reported on the previous Section. Thus, it indicates that up to $\sim6\%$ of these objects can be true cluster members. From these objects, one half have completely observed values, thus 3\% of our new candidates are completely observed objects. This last figure agrees perfectly well with the 3\% of non recovered members reported by \citet{Sarro2014}. 

In Figs. \ref{figure:newones} and \ref{figure:rejecteds} I show the proper motions and $K_s$ vs $i-K_s$ CMD projection spaces of our new candidates and the rejected ones  of \citet{Bouy2015}. In the following I elaborate on their properties.

UNITS WITHIN MATHEMATICAL EXPERSSION.

MEDIAN SYMBOL? SUBINICES? CHANGE ALSO IN THE PAPER.

The new candidate members have proper motions uncertainties whose median, $\overline{\mu_{\alpha,\delta}}=\{1.33,1.33\} \ \ mas/yr$, is two times larger than those of the candidate members in common with \citet{Bouy2015}, median $\overline{\mu_{\alpha,\delta}}=\{0.65,0.65\} \ \ mas/yr$. Also, as shown by Fig. \ref{figure:newones}, the majority of the new candidate members, 148, have probabilities lower than 0.95, are located in a halo around the locus of the cluster proper motions, and on top of the cluster sequence in the $K_s$ vs $i-K_s$ CMD. On the contrary, the new candidates with probabilities higher than 0.95, which are 39, lay in the centre of the cluster proper motions and fall above the cluster sequence in the $K_s$ vs $i-K_s$ CMD. Thus, I hypothesise that: i) Objects whose photometry is compatible with the cluster sequence but are in the proper motions halo, have higher membership probabilities in our methodology due to the increased flexibility of the cluster proper motions model: it now has four gaussians instead of the two of \citet{Bouy2015}. And ii) objects near the centre of the cluster proper motions but located above the cluster photometric sequence sequence, are multiple systems \cite[probably triple systems which can amount to 4\% of the population][]{Duquennoy1991} with an increased membership probability due to our more flexible photometric model of the cluster and equal-mass binaries sequences.

The rejected candidates of \citet{Bouy2015}, as it is shown in Figs. \ref{figure:rejecteds} and \ref{figure:rejectedsCOLORS}, have proper motions uncertainties with median $\overline{\mu_{\alpha,\delta}}=\{3.15,3.19\} \ \ mas/yr$. This value is more than four times larger than that of the candidates in common with our members. Also, these objects are distributed along the cluster sequence. Among these objects, those with a relatively high membership probability occur mostly at the middle of the cluster sequence (green squares of Fig. \ref{figure:rejectedsCOLORS}) while those with lower membership probabilities occur at the bright and faint ends (blue and red triangles of Fig. \ref{figure:rejectedsCOLORS}, respectively). These last regions coincide with those where the missing values happen the most. We stress the fact that \citet{Sarro2014} and later \citet{Bouy2015} construct their models using only completely observed objects (i.e. those without missing values). For their field models both authors use a sample of $\approx 20,000$ objects. Proceeding in that way, as explained in Sect. \ref{sect:missing}, underestimates the field density, particularly in the regions where the missing values are more frequent. Underestimating the field likelihood increases in the cluster field likelihood ratio, therefore it increases also the cluster membership probabilities. Furthermore, the proper motions uncertainties of objects at the bright middle and faint ends, have medians of $\overline{\mu_{\alpha,\delta}}=\{4.0,4.2\} \ \ mas/yr$, $\overline{\mu_{\alpha,\delta}}=\{2.4,2.4\} \ \ mas/yr$ and $\overline{\mu_{\alpha,\delta}}=\{3.4,3.4\} \ \ mas/yr$, respectively. These figures are approximately 6, 4 and 5 times larger, respectively, than those of the candidates in common. These large uncertainties produce a proportional spread of the likelihood distribution thus further reducing the membership probability.

I consider that both the large proper motion uncertainties and field likelihoods are responsible for the diminished membership probabilities of \citet{Bouy2015} rejected candidates. However, these rejected candidate members cannot be discarded as potential members. Indeed, at the probability threshold of maximum accuracy, $p_t=0.84$, the TPR is just $90.0\pm0.05$\%. It means that there are still 10\% of true members within the rejected candidates. To rule out the possibility that these objects are indeed members we need lower proper motion uncertainties and fewer missing values. Future steps will be taken to try to solve this issue.

Summarising, the discrepancies between our individual membership probabilities and those reported by \citet{Bouy2015} arise from subtle but important differences. The first of them is the more formal treatment of missing values in our methodology and its inclusion in the field model. Taking into account the missing values has two main consequences. The first of them is that, the new photometric model of the field diminished membership probabilities, particularly in the regions where missing values happen the most. Second, the use of missing values in the construction of the cluster model allow us to include the information of good candidate members that were otherwise discarded a priori. The second difference is the higher flexibility of our cluster model, it allows us to increase the membership probability of the previously discarded candidates. Furthermore, as shown by the red squares in the upper left corner of Fig. \ref{figure:HM-SBB}, the higher flexibility of our cluster model allow us to include as new candidate members previously rejected objects with complete (non-missing) values.  

\begin{figure}[htbp]
\begin{center}
%\resizebox{\hsize}{!}{\includegraphics{figs/HBMvsBouy.pdf}}
\caption{Recovered membership probabilities compared to those of \citet{Bouy2015}. Lines show the 0.75 and $p_t=0.84$ probability thresholds used in both works. The numbers indicate the new candidate members (top left), rejected candidate members (bottom right), and common candidate members (top right).}
\label{figure:HM-SBB}
\end{center}
\end{figure}


 \begin{figure*}[htbp]
\begin{center}
%\resizebox{\hsize}{!}{\includegraphics[page=1]{figs/NewOnes.pdf}\includegraphics[page=5]{figs/NewOnes.pdf}}
\caption{Proper motion (left) and $K_s$ vs. $i-K_s$ CMD (right) showing the new candidate members found in this work. XXXXX.}
\label{figure:newones}
\end{center}
\end{figure*}

 \begin{figure*}[htbp]
\begin{center}
%\resizebox{\hsize}{!}{\includegraphics[page=1]{figs/Rejecteds.pdf}\includegraphics[page=5]{figs/Rejecteds.pdf}}
\caption{Proper motion (left) and $K_s$ vs. $i-K_s$ CMD (right) showing the rejected candidate members of \citet{Bouy2015}. Captions as in Fig. \ref{figure:newones}.}
\label{figure:rejecteds}
\end{center}
\end{figure*}

\begin{figure*}[htbp]
\begin{center}
%\resizebox{\hsize}{!}{\includegraphics[page=1]{figs/RejectedsCOLORS.pdf}\includegraphics[page=5]{figs/RejectedsCOLORS.pdf}}
\caption{Proper motion (left) and $K_s$ vs. $i-K_s$ CMD (right) showing the rejected candidate members of \citet{Bouy2015}. The colours and shapes are a proxy for their $K_s$ magnitude.}
\label{figure:rejectedsCOLORS}
\end{center}
\end{figure*}

 
\section{The statistical distributions of the Pleiades cluster.}
Once the objective probability threshold has been established and the results of the classification analysed and compared with the literature. Now I present the results of the statistical distributions that describe the cluster population. These distributions result directly or indirectly from the posterior distribution of the parameters in our model. Here I summarise these parametric posterior distributions, together with some of their correlations. Also, I present and analysis on the way these posterior distribution help us to update our prior knowledge.

In Table \ref{tab:params} I summarise the posterior distribution of the parameters in our model. I use as statistic and uncertainty the mode and the 16th and 84th percentiles, respectively. The parameter names correspond to those given in Sect. \ref{sect:priors}. 


%\input{background/Tables/TableParameters.txt}

\section{Updating the prior knowledge}
As mentioned by \citet{Gelman2006}, the posterior distribution must be inspected to update our previous knowledge. To inspect these posterior distribution, I use the bare values and the correlations among them. The values indicate, for example, that the number of  GMM modelling the proper motions of the single stars is overestimated. The fraction and variance of the last gaussian went both to near zero values. A better model would be that in which no computing power will be lost in inferring negligible parameters.

Another simple inspection tells us that our prior for the cluster field fraction is narrow and its mode lay far from that of the posterior distribution. Although this is not wrong since the prior clearly allow this value, this prior must be made wider.  Clearly our prior knowledge underestimated the expected number of cluster members.   

Another useful tool to inspect these posterior distributions is the correlation they show with themselves. In Figure \ref{fig:correlations} I show the correlation matrix of all the parameters in our model. This Fig. shows elements that could be considered to improve our model. 
For example, the large correlation shown by the high order coefficients of the spline series may indicate that we can save some of these parameters.   

\begin{figure}[htbp]
\begin{center}
%\includegraphics[width=\textwidth]{./background/Figures/Correlations.pdf}
\caption{Correlation matrix of parameters in our model. The colour code indicates the value of the correlation coefficient.}
\label{fig:correlations}
\end{center}
\end{figure}

In the following Sections, I use the distributions of the parameters in our model to derive the statistical distributions that describe the cluster population. Some of these distributions have as parameters those inferred in the model, however, other, like the mass distribution require more elaborated derivations.  

Discuss how to deal with future clusters in which we will not have Bouy2015 for the priors.

IS BIC a good approximation, what can be done in the future?

\section{Velocity distribution}
I must work on it. Here I must transform the bivariate proper motions distributions into a univariate velocity distributions using the distance and assuming spherical symmetry. This distribution will give us some hints to improve the proper motions model. It will be interesting to fit a model, maxwellian for example and see how well it fits. If more models are available we can try to find the best one in terms of Bayesian model selection. 
\section{Spatial distribution}
To include
\section{Luminosity distribution}
\label{sect:luminosity}
This Section describes the process by which the apparent $J,H$, and $K_s$ magnitude distributions are obtained and then transformed into the absolute magnitude distributions. Later, I present  these distributions and compare them with those found by \citet{Bouy2015}. Also I will compare them with the ones resulted from only the high membership probability objects.
\subsection{Derivation of the magnitude distributions}
\label{subsect:deriveluminosity}
To derive the $J,H,K_s$ magnitude distributions I start with the colour index, $CI$, distribution. This last one, is described by an univariate GMM whose parameters are inferred in the model. Since we also model the EMB, their fraction and photometric sequence are taken into account. 

In the following, I exemplify the process of derivation on the $K_s$ band. Similar transformations apply to the rest of the bands. 
To obtain the distribution of $K_s$ for the cluster objects, I take the colour index $CI$ as a nuisance parameter, later I marginalise it. Thus, 
REMOVE CI FROM PCI IT IS OBVIUS.

MARGINALISATION OF CI OVER CI OBSERVED.
\begin{align}
p(K_s | \boldsymbol{\theta}_c) & = \int p(K_s,CI | \boldsymbol{\theta}_c) \cdot dCI =  \int p(K_s | CI ,\boldsymbol{\theta}_c) \cdot p(CI|\boldsymbol{\theta}_c)\cdot dCI. \nonumber
\end{align}
The term $p(K_s | CI ,\boldsymbol{\theta}_c)$ corresponds to the GMM modelling the distribution of $CI$ (Eq. \ref{eq:colordist}), while $p(K_s | CI ,\boldsymbol{\theta}_c)$ is the probability of $K_s$ given the $CI$, and the cluster parameters $\boldsymbol{\theta}_c$. The EMB are included with an amplitude equal to their fraction, ($1-\pi_{CB}$). Thus,

\begin{align}
p(K_s | \boldsymbol{\theta}_c) & =  \int \left[\pi_{CB}\cdot p_{Cs}(K_s| CI, \boldsymbol{\theta}_c) + (1-\pi_{CB})\cdot p_{Bs}(K_s| CI, \boldsymbol{\theta}_c)\right]\nonumber \\& \cdot p_{CI}(CI|\boldsymbol{\theta}_c)\cdot dCI. \nonumber \\
& =   \pi_{CB} \int p_{Cs}(K_s| CI, \boldsymbol{\theta}_c) \cdot p_{CI}(CI|\boldsymbol{\theta}_c) dCI \nonumber \\
&+ (1-\pi_{CB})\int p_{Bs}(K_s| CI, \boldsymbol{\theta}_c) \cdot p_{CI}(CI|\boldsymbol{\theta}_c)\cdot  dCI. \nonumber \\
\end{align}

In this equation, $Cs$ and $Bs$ stand for cluster and EMB sequences, respectively. The terms inside the integrals correspond to Equations \ref{eq:lik-seq} and \ref{eq:colordist}. However, since here I want to derive only the distribution of $K_s$, I marginalise the rest of the bands. Also, the integration limits must change to those of the truncated colour distribution ($CI_{min}=0.8, CI_{max}=8$). Hence,

\begin{align}
&p(K_s | \boldsymbol{\theta}_c)  =   \pi_{CB} \int_{CI_{min}}^{CI_{max}}\left[ \left[\sum_{i=1}^5 \pi_{CI,i} \cdot \mathcal{N}_t(CI| \mu_{CI,i},\sigma_{CI,i})\right]\right. \nonumber \\
&\cdot  \left.\int_{\tilde{Y},\tilde{J},\tilde{H}}\mathcal{N}(\{CI,\tilde{Y},\tilde{J},\tilde{H},K_s\}|\boldsymbol{\mathcal{S}}(CI, \boldsymbol{\beta}),\Sigma_{clus})~d\tilde{Y}~d\tilde{J}~d\tilde{H}\right] \cdot dCI \nonumber \\
& + (1-\pi_{CB}) \int_{CI_{min}}^{CI_{max}}\left[\left[\sum_{i=1}^5 \pi_{CI,i} \cdot \mathcal{N}_t(CI| \mu_{CI,i},\sigma_{CI,i})\right]\right.\nonumber\\
&\cdot \left. \int_{\tilde{Y},\tilde{J},\tilde{H}}\mathcal{N}(\{CI,\tilde{Y},\tilde{J},\tilde{H},K_s\}|T_{Bs}(\boldsymbol{\mathcal{S}}(CI, \boldsymbol{\beta})),\Sigma_{clus})~d\tilde{Y}~d\tilde{J}~d\tilde{H}\right]\cdot dCI. \nonumber 
\end{align}

The derivations of the $J$ and $H$ magnitude distributions are similar to the procedure described for $K_s$. It is worth of notice that, the derivation process takes into account the EMB and the systems (binaries or multiples) which could have different mass ratios. Therefore, we call them the system magnitude distributions. 

The previous magnitude distributions, together with the parallax and extinction of the cluster, allows us to obtain the system luminosity distributions. Here, I assume that the parallax is normally distributed with mean, 7.44 mas, and standard deviation 0.42 mas \citep{Galli2017}. This parallax distribution is then convolved with the magnitude distributions to obtain the absolute magnitude distributions. Finally, I deredden them employing the canonical value of extinction: $A_v=0.12$ \citep{Guthrie1987}. This last values were transformed into the $J,H,K_s$ extinctions using the extinction law of \citet{Cardelli1989}.

Our methodology prescribes the \emph{true} photometric quantities based on the \emph{true} colour index $CI$. Therefore, the completeness limits of this $CI$ dictate those of the photometric bands. The upper completeness limits that \citet{Bouy2015} estimate for $i$ and $K_s$ are $i\approx23$ mag and $K_s\approx18$ mag (see their appendix A). As these authors mention, due to the heterogeneous origins of the DANCe DR2 survey, the completeness is not homogeneous over its entire area. To overcome this issue, they identified a region, the inner three degrees of the cluster, with homogeneous spatial and depth coverage. Then, they restricted their analysis to this region. 

Restricting the sample means that good candidate members are not taken into account. Furthermore, if any dynamical process has been set on the cluster such that the mass distribution of its members is not uniform in the space, then restricting the sample could introduce a bias. One of such dynamical process is mass segregation, which, as suggested by \citet{Adams2001} may have happen in the Pleiades. 

Instead of restricting the sample, I assume that the UKIDSS survey, which is the most profound of the DANCe catalogue, provides the homogeneous spatial coverage at faint magnitudes, thus providing the lower limit to the completeness. Then, for the bright end of the survey, I quote conservative completeness limits. Figure \ref{figure:completeness} shows the $K_s$ and $i$ density  for all sources in the Pleiades DANCe DR2. The upper completeness limits correspond to the point with maximum density, $i=21.4$ mag, $K_s=18.1$ mag. The density at bright magnitudes shows a sharp decline, probably due to saturation. Therefore, I choose $i=13.2$ mag and $K_s=11.0$ mag as the lower completeness limits.

The $CI$ completeness interval is then defined as that of all the points, along the cluster sequence in the $K_s$ vs. $i-K_s$ CMD, for which $i$ and $K_s$ are bounded by their upper and lower completeness limits, respectively. This results in a completeness interval for $i-K_s$ of  $2.7<i-K_s<5.6$ mag. With this completeness interval and the cluster sequence (the splines), we derive the completeness intervals for the $J,H,K_s$. Finally, these intervals were transformed to absolute magnitudes and deredden. 
\begin{figure}[htbp]
\begin{center}
%\resizebox{\hsize}{!}{\includegraphics{figs/Density-Kvsi.pdf}}
\caption{Density of all DANCe DR2 sources in $K_s$ vs $i$ magnitudes. Lines show our completeness limits, $13.2<i<21.4$ mag and $11<K_s<18.1$ mag. The grey area is considered incomplete.}
\label{figure:completeness}.
\end{center}
\end{figure}


In Fig. \ref{figure:Luminosities}, I plot the $J,H,K_s$ luminosity distributions together with their completeness limits, hereafter I call these distributions the continuous BHM. For the sake of comparison I also show the following luminosity distributions. The luminosity distributions of objects whose mode of membership probability is greater than our probability threshold $p_t=0.84$, I call these distributions the discrete BHM. Also, I plot the luminosity distribution resulting from the candidate members of \citet{Bouy2015}, I call it discrete Bouy. Since the discrete luminosity distributions, both Bouy and BHM, relay on the individual object magnitudes, and many of these objects have missing values, I impute them using the nearest euclidean neighbour. 

The difference between the continuous BHM  and discrete BHM distributions comes essentially from the objects used to obtain them. The continuous one uses all objects proportionally to their cluster membership probability while the discrete BHM uses only the high probability candidate members ($p>p_t$). Since the discrete BHM is not a random sample of the continuous BHM, therefore their distributions does not need to be exactly alike. In addition, the missing values in the continuous BHM case were marginalised, while in the discrete BHM were imputed.
 
On the other hand, the differences between the discrete distributions, BHM and that of \citet{Bouy2015}, arise mainly at the bright and faint ends ($K_s\approx 4$ mag and $K_s\approx11$ mag). We argue that the origin of these differences lay in our new candidate members and in the rejected ones of \citet{Bouy2015}, as it is discussed in Sect. \ref{sect:comparisonBouy}.

\begin{figure}[htbp]
\begin{center}
%\resizebox{\hsize}{!}{\includegraphics{figs/absolute_JHK-log.pdf}}
\caption{Luminosity functions from $J,H,K_s$ (orange). Also shown the regions of incompleteness and the luminosity functions computed from: the candidate members of \citet{Bouy2015} (dot-dashed blue line), and our candidate members, ($p_{84\%}>p_t$, dashed black line).}
\label{figure:Luminosities}.
\end{center}
\end{figure}

\section{Mass distribution}
This Section starts with a brief description of the mass-luminosity relation, which is used to derive the present day system mass function (PDSMF) of the Pleiades together with the luminosity distribution of the previous section. Then I compare this PDSMF to the Initial Mass Functions (IMFs) of \citet{Chabrier2005} and \citet{Thies2007}. Later, I conclude this section with an analysis of some simple models that can be fitted to our the PDSMF, I give the best model according to the Bayesian evidence.

\subsection{The mass-luminosity relation}
\label{sect:mass-luminosity}
The mass-luminosity relation is the key to transform luminosities into masses. This relation relies entirely on the current models of stellar atmosphere and evolution. Among the different flavours of models, we choose the BT-Settl model of \citet{Allard2012}. We based this decision on the fact that currently, this is the only model which covers our luminosity range at the age of the Pleiades. Since the DANCe survey uses as reference the $J,H$ and $K_s$ bands of the 2MASS survey, I choose the BT-Settle grid: CIFIST2011bc for the 2MASS AB photometric system. This grid, as it name indicates, returns values of the luminosity on a (non-uniform) grid on the mass. However,  the transformation of luminosities into masses is proportional and thus very sensitive to the Jacobian of the transformation. To avoid the discontinuities in the derivatives produced by the grid, we decided to fit the grid using spline series and then obtain the derivative from these series. It is important to notice that we implicitly assume that the transformation from luminosities to masses does not have any associated uncertainty, thus it is uniquely determined. We can not do more since the models do not provide any uncertainty. 

\subsection{Present day mass function}

The PDSMF is independently obtained in the $J,H,K_s$ bands by transforming the luminosity functions into system mass functions using the mass-luminosity relations described in the previous section. Since the luminosity functions of Sect. \ref{sect:luminosity} correspond to the luminosity of systems (single and binary stars altogether), therefore the derived mass function corresponds to the system mass function. We assume an age of 120 Myr for the Pleiades together with solar metallicity, these are the canonical values reported by \citet{} and \citet{}, respectively.

Figure \ref{fig:MassFunction} shows the logarithmic PDSMF ($\xi_L$) for the $J,H,K_s$ bands normalised on the completeness limits obtained in Sect. \ref{sect:luminosity}. This figure also shows, the PDSMF proposed by  \citet{Bouy2015} and, the IMFs of \citet{Thies2007} and \citet{Chabrier2005}. For this last IMF, I show the standard uncertainty as the value reported by \citet{Chabrier2003}. As shown in this Fig., our PDSMFs compares well, in the completeness interval, with the one proposed by \citet{Bouy2015}. However, there are discrepancies, particularly above $0.3 M_{\odot} (-0.5 < \log M/M_{\odot})$. These may have its origin on the higher membership probability of our new candidate members. These new candidate members are preferentially M stars, whose masses are the range $0.075 - 0.6 M_{\odot}$ ($-1.12 < \log M/M_{\odot} < -0.22$). Furthermore, these differences root also on the objects that \citet{Bouy2015} did not include in their analysis: those lying outside the inner three degree region. 

To obtain a  model for our PDSMF I proceed as follows. First, I select three models: a log-normal distribution and two power-law distributions of the form $m^{-\alpha}$, with two and three power-law segments. Second, I took the mode distribution of our 100 sample distributions of the PDSMF in the $K_s$ band and completeness interval and draw a $10^4$ synthetic sample. Afterwards, using \emph{PyMultiNest} \citep{Buchner2014}, and the synthetic sample I fitted the three models. Finally, in Table \ref{tab:fitPDSMF}, I give the posterior distributions of each model parameters together with its evidence (see Sect. \ref{sect:modelselection}).

Judging by the evidences, the best model corresponds to the two segment power-law distribution. This model is over plot as solid black line in Fig. \ref{fig:MassFunction}. This model agrees well with that found by \citet{Bouy2015}, except for the flat part in the low-mass range and the less steep slope in the high mass range. Nevertheless, it is in clear discrepancy with the IMFs of \citet{Chabrier2005},  \cite[$m_c=0.25_{-0.016}^{+0.021}$ and $\sigma=0.55_{-0.01}^{+0.05}$, the uncertainties are those reported by][for single objects]{Chabrier2003} and of \citet{Thies2007}. The discrepancy between the IMFs and the PDSMFs \cite[][and ours]{Bouy2015} may have its origin on the not yet established uncertainties in the mass-luminosity relationship, on dynamical effects associated with age, or on both of them. In the next section I compare the PDSMF of the Pleiades with that of other younger and older clusters in order to analyse if there is substantial evidence to claim for dynamical effects associated with age.

\begin{table*}[ht!]
\caption{Parameters and evidence of models fitted to the PDSMF}
\begin{center}
\begin{tabular}{lll}
Model&Parameters& Log Evidence\\
\hline
LogNormal&$m_c=0.36\pm0.03$&\\
                 &$\sigma=0.46\pm0.02$ & $18.1 \pm 0.1$\\
\hline
Two Segments &$\alpha_0=-0.11\pm0.06$ \ \ $m \in [0.04,0.22\pm0.01]$ & \\ 
&  $\alpha_1=1.13\pm0.1$ \ \ $m \in [0.22\pm0.01,0.56]$&$2222.7\pm0.4$\\
\hline
Three Segments &$\alpha_0=-0.05\pm0.6$ \ \ $m \in [0.04,0.08\pm0.03]$ & \\
                          &$\alpha_1=-0.1\pm0.1$ \ \ $m \in [0.08\pm0.03,0.22\pm0.01]$ & \\ 
                          &$\alpha_2=1.13\pm0.1$ \ \ $m \in [0.22\pm0.01,0.56]$&$2221.2\pm 0.3$\\
\hline
\end{tabular}
\end{center}
\label{tab:fitPDSMF}
\end{table*}%

Before concluding this section, I use our PDSMF to give a lower limit to the mass of the cluster. The cluster members mean mass, in our entire mass range, is $0.26 \pm 0.006 M_{\odot}$. Thus, the product of this mean mass with the expected number of cluster members, $3116 \pm 110$, is an estimate of mass of the cluster: $807^{+38}_{-29} M_{\odot}$. The expected number of cluster members is the integral, over the whole range of membership probabilities, of number of objects at each membership probability. However, since we still lack the low and high mass ranges of the PDSMF, this value is only a lower limit to the mass of the cluster. As mentioned in Sect. \ref{sect:mass-luminosity}, the uncertainties in the mass-luminosity relations are yet to be established. Thus the quoted uncertainties of our mass results are underestimated.

\begin{figure}[htbp]
\begin{center}
%\resizebox{\hsize}{!}{\includegraphics[page=1]{figs/MassDistribution.pdf}}
\caption{Normalised PDSMF in $J,H,K_s$ bands. Also shown the IMFs of \citet{Chabrier2005, Thies2007} and fits to the PDSMF found by us and \citet{Bouy2015}.}
\label{fig:MassFunction}.
\end{center}
\end{figure}

\section{The mass distribution on time}
In order to test if dynamical effects could be the origin of the discrepancies between the PDSMFs and the IMFs, in this section I analyse the evolution in time of the mass distribution. To do this, I compare the differences between the Pleiades PDSMF ($\approx120$ Myr) and those of the Trapezium and Hyades clusters, which  are $\approx1$ Myr and $\approx 600$ Myr old respectively. These can be thought as snapshots of the Pleiades pasts and future mass functions.  

In Figure \ref{fig:PDSMFcomparison} I compare the PDSMF from the Pleiades derived here, to those of the Trapezium and Hyades. These PDSMFs correspond to those of  Fig. 11 of \citet{Bouy2015} (private communication). As mentioned by \citet{Bouy2015}, the abundance of low-mass stars and brown dwarfs in the range $0.03 - 0.1 \ \ M_{\odot}$($\log M/M_{\odot} \approx \{-1, -1.4\}$) seems to diminish with time. Furthermore, since the PDSMF are normalised, a diminish in the lower mass range produces a relative increase of low-mass stars in the range $-0.4 < \log M/M_{\odot} < -0.2$. The alternative effect of an increase in the high mass range which then may produce a relative diminish in the low mass range, although is statistically possible, is unlikely in the astrophysical sense. Open clusters tend lose stars, not the other way around. Furthermore, this effect is consistent with the classical scenario in which low-mass stars and brown dwarfs are ejected as the cluster relaxes. I test the validity of this scenario, at least the statistical significance of the observed differences among the PDSMF of this three clusters. To perform this test, the null hypothesis is that the Trapezium and the Hyades have the same PDSMF as the Pleiades. Since I only have the inferred model of the Pleiades cluster, I am compelled to perform a frequentist test. Thus, to do the statistical comparison of these three PDSMF I use the Kolmogorov-Smirnov and the Anderson-Darling tests. 

\begin{figure*}[htp]
\begin{center}
%\resizebox{\hsize}{!}{\includegraphics{figs/M45vsM42vsM44.pdf}\includegraphics{figs/CDF_comparison.pdf}}
\caption{Left: PDSMFs of the Pleiades (derived here for $J,H,K_s$ bands), Trapezium, and Hyades, from \citet{Bouy2015}. They are normalised in the interval of completeness.}
\label{fig:PDSMFcomparison}.
\end{center}
\end{figure*}

\begin{figure*}[htp]
\begin{center}
%\resizebox{\hsize}{!}{\includegraphics{figs/CDF_comparison.pdf}}
\caption{Cumulative distribution functions (CDF) of the PDSMFs from left panel and that of \citet{Chabrier2005} and \citet{Thies2007} system initial mass function (normalised also in the interval of completeness). The Pleiades CDF shown is just from $K_s$ band. The grey area depicts the area in which the null hypothesis of same PDSMF as that of the Pleiades can not be rejected (at $\alpha=0.01$).}
\label{fig:PDSMFtest}.
\end{center}
\end{figure*}


Figure \ref{fig:PDSMFtest} shows the cumulative distribution functions (CDFs) of the Trapezium, Pleiades (only in $K_s$ band) and Hyades PDSMFs. Also and for comparison, we show the CDFs of \citet{Chabrier2005} and \citet{Thies2007} IMFs. The grey area around the Pleiades CDF shows the hypothesis test in which I compare each CDF with that of the Pleiades. The null hypothesis,as mentioned before is that each compared CDF is exactly that of the Pleiades. I use the Kolmogorov-Smirnov statistic and the alpha value $\alpha = 0.01$, to compute the maximum vertical distance $d_{\alpha}$ from the Pleiades CDF, the grey region was created with this maximum distance. The null hypothesis is rejected only if the tested CDF lies entirely outside the grey region around the Pleiades CDF. As can be seen, neither the IMFs nor the PDSMF of the Trapezium and Hyades lay entirely within the grey area, thus we can reject the null hypothesis that they share the same PDSMF of the Pleiades. Furthermore, since the Kolmogorov-Smirnov test uses only the maximum distance between CDFs, we also applied the more robust Anderson-Darling test. It also rejects the null hypotheses (at $p < 0.004$) that the Trapezium and Hyades PDSMFs and the \citet{Chabrier2005} and \citet{Thies2007} IMFs have the same CDF of the Pleiades. 

The previous tests show that there is enough evidence to claim for differences among the PDSMFs of these three clusters and from IMFs and Pleiades PDSMF. Thus they suggest that the observed differences may have an origin on dynamical effects associated with age and relaxation. Nevertheless, to claim for reliable evidence supporting these differences the census of the Trapezium and Hyades must be done using the same methods. Also, the uncertainties must be properly establish both for the other PDSMFs and for the mass-luminosity relation from which all these PDSMF are derived. 




